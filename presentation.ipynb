{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9adfd9f",
   "metadata": {
    "id": "e7eaf504"
   },
   "source": [
    "## <font color=blue>Architecture</font>\n",
    "### Overview of data flow\n",
    "#### Data Flow Architecture\n",
    "### Tech Stack\n",
    "* \n",
    "* Docker\n",
    "* Jupyter Lab\n",
    "* Spark Structured Streaming\n",
    "* NiFi\n",
    "* Kafka\n",
    "* Python\n",
    "* Cassandra\n",
    "* Plotly\n",
    "* Dash\n",
    "\n",
    "### End result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57fe56a",
   "metadata": {
    "id": "bd740e6f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abcf1ffd",
   "metadata": {},
   "source": [
    "## <font color=blue>Log Preprocessing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec854b",
   "metadata": {},
   "source": [
    "- Walk thru <a href=\"https://www.w3.org/Daemon/User/Config/Logging.html#common-logfile-format\"> Common Log Format </a>\n",
    "- Parsing Log file\n",
    "- Data Cleaning\n",
    "- Fix the rows with null content_size\n",
    "- Formating timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f328fa2",
   "metadata": {
    "id": "6523b815"
   },
   "source": [
    "## <font color=blue>Extraction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ec6b2",
   "metadata": {
    "id": "c85d6007"
   },
   "source": [
    "### Download Dataset\n",
    "- <a href = https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html> Actual NASA Logs </a>\n",
    "- <a href = https://www.kaggle.com/souhagaa/nasa-access-log-dataset-1995/download> Kaggle </a>\n",
    "- <code>docker exec -i -t nifi bash </br>mkdir -p nasa_logs && cp /opt/workspace/nifi/InputData/data.csv nasa_logs/data.csv</code>\n",
    "\n",
    "### Nifi\n",
    "- Processor\n",
    "- Connection\n",
    "\n",
    "### Kafka\n",
    "- Topic\n",
    "- Producer\n",
    "- Consumer\n",
    "\n",
    "### Topic\n",
    "- Topic creation through CLI\n",
    "\n",
    "#### Commands\n",
    "<code>docker ps</code> to get kafka container name\n",
    "\n",
    "<code>docker exec -i -t kafka bash</code> enter into kafka CLI\n",
    "\n",
    "<code>kafka-topics.sh --create --topic nasa_logs_demo --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:2181</code> creation of topic named nasa_logs_demo\n",
    "\n",
    "<code>kafka-topics.sh --list --bootstrap-server localhost:29092</code> list topics\n",
    "\n",
    "<code>kafka-topics.sh --describe --topic nasa_logs_demo --zookeeper zookeeper:2181</code> describe topic\n",
    "\n",
    "<code>kafka-topics.sh --delete --topic nasa_logs_demo --zookeeper zookeeper:2181</code> delete topic\n",
    "\n",
    "<code>kafka-console-consumer.sh --bootstrap-server localhost:29092 --topic nasa_logs_demo --from-beginning --max-messages 30</code> consume/read data from topic\n",
    "\n",
    "### Streaming data from file system using NiFi\n",
    "- Goto http://localhost:2080/nifi/\n",
    "- Nifi Setup\n",
    "- Publish log data via NiFi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0805c5",
   "metadata": {
    "id": "402a9a13"
   },
   "source": [
    "## <font color=blue>Transformation and Load</font>\n",
    "\n",
    "### Cassandra and HDFS set up\n",
    "- Create namespace and table in Cassandra\n",
    "- CQL Commands\n",
    "<code>\n",
    "    docker exec -i -t cassandra bash\n",
    "    cqlsh -u cassandra -p cassandra\n",
    "    CREATE KEYSPACE IF NOT EXISTS LogAnalysis WITH replication = {'class':'SimpleStrategy', 'replication_factor':1};\n",
    "    CREATE TABLE IF NOT EXISTS LogAnalysis.NASALog (host text , time text , method text , url text , response text , bytes text, extension text, time_added text,PRIMARY KEY (host));\n",
    "    truncate table LogAnalysis.NASALog;\n",
    "</code>\n",
    "- Create a folder in HDFS\n",
    "<code>\n",
    "    docker exec -i -t namenode bash\n",
    "    hdfs dfs -mkdir -p /output1/nasa_logs/\n",
    "    http://localhost:50070/\n",
    "</code>\n",
    "\n",
    "### Read Streaming Data and Cleansing\n",
    "- Schema creation\n",
    "- Reading data from Kafka as Streaming Dataframe\n",
    "- Extraction and cleansing of Log data\n",
    "\n",
    "### Data Loading\n",
    "- Continuous data load to Cassandra\n",
    "- Writing data to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e474a",
   "metadata": {
    "id": "ca51eb02"
   },
   "source": [
    "## <font color=blue>Visualization</font>\n",
    "- Scatter graph and Table definition with intervals using Python Plotly and Dash\n",
    "- Graph and Table app call-back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c16bca",
   "metadata": {
    "id": "83dad3d3"
   },
   "source": [
    "## <font color=blue>Code walkthrough</font>\n",
    "- Log Listener\n",
    "- Log Visualizer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "presentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
